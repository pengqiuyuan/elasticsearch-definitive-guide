[[heap-sizing]]
=== 堆内存:大小和交换

Elasticsearch 默认安装后设置的内存是 1GB。((("deployment", "heap, sizing and swapping")))((("heap", "sizing and setting")))对于任何一个业务部署来说，
这个设置都太小了。如果你正在使用这些默认堆内存配置，您的群集可能会出现问题。

这里有两种方式修改 Elasticsearch 的堆内存。最简单的一个方法就是指定 `ES_HEAP_SIZE` 环境变量。((("ES_HEAP_SIZE environment variable")))服务进程在启动时候会读取这个变量，并相应的设置堆的大小。
比如，你可以用下面的命令设置它：

[source,bash]
----
export ES_HEAP_SIZE=10g
----

此外，你也可以通过命令行参数的形式，在程序启动的时候把内存大小传递给它，如果你觉得这样更简单的话：

[source,bash]
----
./bin/elasticsearch -Xmx10g -Xms10g <1>
----
<1> 确保 (`Xms`) 和 (`Xmx`) 的大小是相同的，防止程序在运行时改变堆内存大小，
这是一个一个非常昂贵的过程。

通常来说，设置 `ES_HEAP_SIZE` 环境变量，比直接写 `-Xmx10g -Xms10g` 更好一点。

==== 把你的内存的一半给 Lucene

一个常见的问题是给 Elasticsearch 配置的内存_太_大了。((("heap", "sizing and setting", "giving half your memory to Lucene")))假设你有一个 64GB 内存的机器，
天啊，我要把 64G 内存全都给 Elasticsearch。因为越多越好啊！

当然，内存对于 Elasticsearch 来说绝对是重要的，用于更多的内存数据
提供更快的操作。但是说到这里，还有另外一个主要的
_内存消耗_大户：Lucene。

Lucene 的设计目的是把底层 OS 里的数据缓存到内存中。((("Lucene", "memory for")))
Lucene的段是分别存储到单个文件中的。因为段是不可变的，
这些文件也都不会变化。所以很利于缓存，同时操作系统也会把这些段文件缓存起来，以便更快的访问。

Lucene 的性能取决于和 OS 的交互。如果你把所有
的内存都分配给 Elasticsearch，不留一点给 Lucene。
那你的全文检索性能会很差的。

最后标准的建议是把 50％的内存给 Elasticsearch，
剩下的 50％也不会没有用处的，Lucene 会很快吞噬剩下的这部分内存。

[[compressed_oops]]
==== 不要超过 32 GB
这里有另外一个原因不分配大内存给 Elasticsearch。事实上((("heap", "sizing and setting", "32gb heap boundary")))((("32gb Heap boundary")))，
JVM 在内存小于 32GB 的时候会采用一个内存对象指针压缩技术。

在 Java 中，所有的对象都分配在堆上。
普通对象（OOP）的指针指向这些对象，指向这些对象的指针大小通常是 CPU 的_字长_的大小：不是 32 bits 就是 64 bits，
这取决于你的处理器，指针指向了你的值的精确位置。

对于 32位的系统，你的内存最大可使用 4 GB。对于 64位的系统，
可以使用更大的内存，但是64位的指针意味着更大的浪费，因为你的指针本身大了。
浪费内存不算什么，更糟糕的是，
更大的指针在主内存和缓存器（例如 LLC，L1等）之间移动数据的时候，会占用更多的带宽。

Java 使用一个叫内存指针压缩的技术 https://wikis.oracle.com/display/HotSpotInternals/CompressedOops[compressed oops]((("compressed object pointers")))
来解决这个问题。它的指针不再表示对象在内存中的精确位置，而是表示 _偏移量_。((("object offsets")))这意味着 32位的指针可以引用 40亿个_对象_，
而不是 40亿个字节。最终，
也就是说堆内存长到 32GB 的物理内存，也可以用 32bit 的指针表示。

一旦你越过那个神奇的 ~32 GB 的边界，指针就会切回普通对象的指针。
每个对象的指针都变长了，就会使用更多的 CPU 内存带宽，也就是说你实际上失去了更多的内存。事实上，当内存到达
40&#x2013;50 GB 的时候，有效内存才相当于使用内存对象指针压缩技术时候的 32 GB 内存。

这段描述的意思就是说：即便你有足够的内存，也尽量不要
超过 32 GB。因为它浪费了内存，降低了 CPU 的性能，还要让 GC 应对大内存。

==== 到底需要低于32GB多少，来设置我的JVM？

遗憾的是，这需要看情况。确切的划分要根据 JVMs 和操作系统的版本情况而定。
如果你想保证其安全可靠，设置堆内存为 `31 gb` 是一个安全的选择。
另外，你可以在你的 JVM 设置里添加 `-XX:+PrintFlagsFinal` 用来验证 `HotSpot JVM` 的临界值，
并且检查 UseCompressedOops 的值是否为 true。对于你自己使用的 JVM 和操作系统版本，这将让你找到最合适的堆内存临界值。

例如，我们在一台安装  Java 1.7 的 MacOSX 上测试，可以看到指针压缩在被禁用之前，最大堆内存大约是在 32600 mb（~31.83 gb）：

[source,bash]
----
$ JAVA_HOME=`/usr/libexec/java_home -v 1.7` java -Xmx32600m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops   := true
$ JAVA_HOME=`/usr/libexec/java_home -v 1.7` java -Xmx32766m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops   = false
----

相比之下，同一台机器安装 Java 1.8，可以看到指针压缩在被禁用之前，最大堆内存大约是在 32766 mb（~31.99 gb）：

[source,bash]
----
$ JAVA_HOME=`/usr/libexec/java_home -v 1.8` java -Xmx32766m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops   := true
$ JAVA_HOME=`/usr/libexec/java_home -v 1.8` java -Xmx32767m -XX:+PrintFlagsFinal 2> /dev/null | grep UseCompressedOops
     bool UseCompressedOops   = false
----

The morale of the story is that the exact cutoff to leverage compressed oops
varies from JVM to JVM, so take caution when taking examples from elsewhere and
be sure to check your system with your configuration and JVM.

Beginning with Elasticsearch v2.2.0, the startup log will actually tell you if your
JVM is using compressed OOPs or not.  You'll see a log message like:

[source, bash]
----
[2015-12-16 13:53:33,417][INFO ][env] [Illyana Rasputin] heap size [989.8mb], compressed ordinary object pointers [true]
----

Which indicates that compressed object pointers are being used.  If they are not,
the message will say `[false]`.


[role="pagebreak-before"]
.我有一个1TB 内存的机器！
****
这个 32GB 的线是很很重要的。那如果你的机器有很大的内存怎么办呢？
现在的机器内存普遍增长，你现在都可以看到有 512&#x2013;768 GB
内存的机器。

首先，我们建议避免使用这样的高配机器(see <<hardware>>)。

但是如果你已经有了这样的机器，你有两个可选项：

- 你主要做全文检索吗？考虑给 Elasticsearch 不超过 32 GB 的内存
剩下的交给Lucene用作操作系统的文件系统缓存。所有的内存
都用来缓存 segments，会加快全文检索。

- 你需要更多的排序和聚合？你希望更大的堆内存。
你可以考虑一台机器上创建两个或者更多 ES 节点，而不要部署一个使用或者超过 32 GB 内存的节点。
仍然要坚持 50％ 原则。假设你有个机器有 128 GB 的内存，
你可以创建两个节点，每个节点内存分配不超过 32 GB。
也就是说不超过 64GB 内存给 ES 的堆内存，剩下的超过 64GB 的内存给 Lucene。
+
如果你选择第二种，你需要配置 `cluster.routing.allocation.same_shard.host: true`
。这会防止同一个 shard 的主副本存在同一个物理机上（因为如果存在一个机器上，副本的高可用性就没有了）。
****

==== Swapping 是性能的坟墓

这是显而易见的，((("heap", "sizing and setting", "swapping, death of performance")))((("memory", "swapping as the death of performance")))((("swapping, the death of performance")))但是还是有必要说的更清楚一点：内存交换
到磁盘对服务器性能来说是致命的。想想看：一个内存的操作必须是快速的。

如果内存交换到磁盘上，一个100微秒的操作可能变成10毫秒。
再想想那么多10微秒的操作时延累加起来。
不难看出 swapping 对于性能是多么可怕。

最好的办法就是在你的操作系统中完全禁用 swap。这样可以暂时禁用：

[source,bash]
----
sudo swapoff -a
----

这样可以暂时禁用，你可能需要修改 `/etc/fstab` 文件，这要参考你的操作系统相关文档。

如果对你来说并不能完全禁用 swap，你可以降低 `swappiness` 的值。
这个值决定操作系统交换内存的频率。
这可以预防正常情况下发生交换，但仍允许os在紧急情况下发生交换。

对于大部分Linux操作系统，可以在 `sysctl` 中这样配置：

[source,bash]
----
vm.swappiness = 1 <1>
----
<1> `swappiness` 设置为 `1` 比设置为`0`要好，因为在一些内核版本 `swappiness` 设置为 `0` 会引发 OOM（内存溢出）。

最后，如果上面的方法都不能做到，你需要打开配置文件中的 `mlockall` 开关。
它的作用就是运行 JVM 锁住内存，禁止 OS 交换出去。在你的 `elasticsearch.yml` 文件中，设置如下：

[source,yaml]
----
bootstrap.mlockall: true
----
