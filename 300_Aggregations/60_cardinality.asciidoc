[[cardinality]]
=== 查找唯一值的数目（Finding Distinct Counts）

Elasticsearch 提供的首个近似聚合是 `cardinality` （注：基数）度量。
((("cardinality", "finding distinct counts")))((("aggregations", "approximate", "cardinality")))((("approximate algorithms", "cardinality")))((("distinct counts"))) 它提供一个字段的基数，即该字段的 _distinct_ 或者 _unique_ 值的数目。
((("unique counts"))) 可能会对 SQL 形式比较熟悉：

[source, sql]
--------
SELECT COUNT(DISTINCT color)
FROM cars
--------

Distinct 计数是一个普通的操作，可以回答很多基本的商业问题：

- 网站的独立访问用户是多少？
- 卖了多少种汽车？
- 每月有多少独立用户购买了商品？

我们可以用 `cardinality` 度量确定经销商销售汽车颜色的种类：

[source,js]
--------------------------------------------------
GET /cars/transactions/_search
{
    "size" : 0,
    "aggs" : {
        "distinct_colors" : {
            "cardinality" : {
              "field" : "color"
            }
        }
    }
}
--------------------------------------------------
// SENSE: 300_Aggregations/60_cardinality.json

返回的结果表明已经售卖了三种不同颜色的汽车：

[source,js]
--------------------------------------------------
...
"aggregations": {
  "distinct_colors": {
     "value": 3
  }
}
...
--------------------------------------------------

可以让我们的例子变得更有用：每月有多少颜色的车被售出？为了得到这个度量，我们只需要将一个 `cardinality` 度量嵌入一个 ((("date histograms, building"))) `date_histogram` ：

[source,js]
--------------------------------------------------
GET /cars/transactions/_search
{
  "size" : 0,
  "aggs" : {
      "months" : {
        "date_histogram": {
          "field": "sold",
          "interval": "month"
        },
        "aggs": {
          "distinct_colors" : {
              "cardinality" : {
                "field" : "color"
              }
          }
        }
      }
  }
}
--------------------------------------------------
// SENSE: 300_Aggregations/60_cardinality.json

==== 学会权衡（Understanding the Trade-offs）
正如我们本章开头提到的， `cardinality` 度量是一个近似算法。
((("cardinality", "understanding the tradeoffs"))) 它是基于 http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf[HyperLogLog++] （HLL）算法的。((("HLL (HyperLogLog) algorithm")))((("HyperLogLog (HLL) algorithm")))
HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。

我们不需要理解技术细节（如果确实感兴趣，可以阅读这篇论文），((("memory usage", "cardinality metric"))) 但我们最好应该关注一下这个算法的 _特性_ ：

- 可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）。
- 对于低基数集能够达到高准确度。
- 固定的内存使用。即使有几千或甚至上百亿的唯一值，内存的使用也只是依赖于配置里的精度要求。

要配置精度，我们必须指定 `precision_threshold` 参数的值。((("precision_threshold parameter (cardinality metric)")))
这个阀值定义了在何种基数水平下我们希望得到一个近乎精确的结果。参考以下示例：

[source,js]
--------------------------------------------------
GET /cars/transactions/_search
{
    "size" : 0,
    "aggs" : {
        "distinct_colors" : {
            "cardinality" : {
              "field" : "color",
              "precision_threshold" : 100 <1>
            }
        }
    }
}
--------------------------------------------------
// SENSE: 300_Aggregations/60_cardinality.json
<1> `precision_threshold` 接受 0–40，000 之间的数字，更大的值还是会被当作 40，000 来处理。

示例会确保当字段唯一值在 100 以内时会得到非常准确的结果。尽管算法是无法保证这点的，但如果基数在阀值以下，几乎总是 100% 正确的。高于阀值的基数会开始节省内存而牺牲准确度，同时也会对度量结果带入误差。

对于指定的阀值，HLL 的数据结构会大概使用内存 `precision_threshold * 8` 字节，所以就必须在牺牲内存和获得额外的准确度间做平衡。

在实际应用中， `100` 的阀值可以在唯一值为百万的情况下仍然将误差维持 5% 以内。

==== 速度优化（Optimizing for Speed）
如果想要获得唯一数目的值， _通常_ 需要查询整个数据集合（或几乎所有数据）。((("cardinality", "optimizing for speed")))((("distinct counts", "optimizing for speed"))) 所有基于所有数据的操作都必须迅速，原因是显然的。
HyperLogLog 的速度已经很快了，它只是简单的对数据做哈希以及一些位操作。((("HyperLogLog (HLL) algorithm")))((("HLL (HyperLogLog) algorithm")))

但如果速度对我们至关重要，可以做进一步的优化。
因为 HLL 只需要字段内容的哈希值，我们可以在索引时就预先计算好。((("hashes, pre-computing for cardinality metric"))) 就能在查询时跳过哈希计算然后将数据信息直接加载出来。

[NOTE]
=========================
预先计算哈希值只对内容很长或者基数很高的字段有用，计算这些字段的哈希值的消耗在查询时是无法忽略的。


尽管数值字段的哈希计算是非常快速的，存储它们的原始值通常需要同样（或更少）的内存空间。这对低基数的字符串字段同样适用，Elasticsearch 的内部优化能够保证每个唯一值只计算一次哈希。

基本上说，预先计算并不能保证所有的字段都快，它只对那些具有高基数和内容很长的字符串字段有作用。需要记住的是预先计算也只是简单地将代价转到索引时，代价就在那里，不增不减。
=========================

要想这么做，我们需要为数据增加一个新的多值字段。我们先删除索引，再增加一个包括哈希值字段的映射，然后重新索引：

[source,js]
----
DELETE /cars/

PUT /cars/
{
  "mappings": {
    "transactions": {
      "properties": {
        "color": {
          "type": "string",
          "fields": {
            "hash": {
              "type": "murmur3" <1>
            }
          }
        }
      }
    }
  }
}

POST /cars/transactions/_bulk
{ "index": {}}
{ "price" : 10000, "color" : "red", "make" : "honda", "sold" : "2014-10-28" }
{ "index": {}}
{ "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" }
{ "index": {}}
{ "price" : 30000, "color" : "green", "make" : "ford", "sold" : "2014-05-18" }
{ "index": {}}
{ "price" : 15000, "color" : "blue", "make" : "toyota", "sold" : "2014-07-02" }
{ "index": {}}
{ "price" : 12000, "color" : "green", "make" : "toyota", "sold" : "2014-08-19" }
{ "index": {}}
{ "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" }
{ "index": {}}
{ "price" : 80000, "color" : "red", "make" : "bmw", "sold" : "2014-01-01" }
{ "index": {}}
{ "price" : 25000, "color" : "blue", "make" : "ford", "sold" : "2014-02-12" }
----
// SENSE: 300_Aggregations/60_cardinality.json
<1> 多值字段的类型是 `murmur3` ，这是一个哈希函数。

现在当我们执行聚合时，我们使用 `color.hash` 字段而不是 `color` 字段：

[source,js]
--------------------------------------------------
GET /cars/transactions/_search
{
    "size" : 0,
    "aggs" : {
        "distinct_colors" : {
            "cardinality" : {
              "field" : "color.hash" <1>
            }
        }
    }
}
--------------------------------------------------
// SENSE: 300_Aggregations/60_cardinality.json
<1> 注意我们指定的是哈希过的多值字段，而不是原始字段。

现在 `cardinality` 度量会读取 `"color.hash"` 里的值（预先计算的哈希值），并将它们作为原始值的动态哈希值。

每个文档节省的时间有限，但如果哈希每个字段需要 10 纳秒而我们的聚合需要访问一亿文档，那么每个查询就需要多花 1 秒钟的时间。如果我们发现自己在很多文档都会使用 `cardinality` 基数，可以做些性能分析看是否有必要在我们部署的应用中采用预先计算哈希的方式。
